{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d636c3f-cab9-4d94-984f-f7e87f5b70fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['22', 'huge', 'fan', 'fare', 'big', 'talking', 'leave', 'chaos', 'pay', 'disputes', 'get', 'allshowandnogo']\n",
      "[2/2] huge fan fare and big talking before they leave. chaos and pay disputes when they get there. #allshowandnogo  \n",
      "(31962, 47386)\n",
      "(31962,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fatal Python error: PyEval_RestoreThread: the function must be called with the GIL held, but the GIL is released (the current Python thread state is NULL)\n",
      "Python runtime state: initialized\n",
      "\n",
      "Thread 0x00007000127ea000 (most recent call first):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ipykernel/parentpoller.py\", line 40 in run\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 1038 in _bootstrap_inner\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 995 in _bootstrap\n",
      "\n",
      "Thread 0x0000700011764000 (most recent call first):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 320 in wait\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 622 in wait\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/IPython/core/history.py\", line 884 in run\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/IPython/core/history.py\", line 60 in only_when_enabled\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/decorator.py\", line 232 in fun\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 1038 in _bootstrap_inner\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 995 in _bootstrap\n",
      "\n",
      "Thread 0x0000700010761000 (most recent call first):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/selectors.py\", line 561 in select\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 1873 in _run_once\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 604 in run_forever\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195 in start\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ipykernel/control.py\", line 23 in run\n",
      "  File \"/Library/"
     ]
    }
   ],
   "source": [
    "\n",
    "# https://www.kaggle.com/datasets/durgeshrao9993/twitter-analysis-dataset-2022\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from textblob import TextBlob\n",
    "import string\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"TkAgg\")\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "# Load the synthetic dataset\n",
    "df = pd.read_csv(\"/Users/shraddha/Documents/UEL/MYDES/twitter.csv\")\n",
    "\n",
    "# df.hist(bins = 30, figsize = (13,5), color = '#016A70')\n",
    "# plt.show()\n",
    "\n",
    "# Let's define a pipeline to clean up all the messages \n",
    "# The pipeline performs the following: (1) remove punctuation, (2) remove stopwords\n",
    "def message_cleaning(message):\n",
    "    Test_punc_removed = [char for char in message if char not in string.punctuation]\n",
    "    Test_punc_removed_join = ''.join(Test_punc_removed)\n",
    "    Test_punc_removed_join_clean = [word for word in Test_punc_removed_join.split() if word.lower() not in stopwords.words('english')]\n",
    "    return Test_punc_removed_join_clean\n",
    "\n",
    "# Let's test the newly added function\n",
    "tweets_df_clean = df['tweet'].apply(message_cleaning)\n",
    "\n",
    "print(tweets_df_clean[5]) # show the cleaned up version\n",
    "\n",
    "print(df['tweet'][5]) # show the original version\n",
    "\n",
    "# Define the cleaning pipeline we defined earlier\n",
    "vectorizer = CountVectorizer(analyzer = message_cleaning, dtype = np.uint8)\n",
    "tweets_countvectorizer = vectorizer.fit_transform(df['tweet'])\n",
    "\n",
    "vectorizer.get_feature_names_out()\n",
    "\n",
    "tweets = pd.DataFrame(tweets_countvectorizer.toarray())\n",
    "\n",
    "X = tweets\n",
    "\n",
    "y = df[\"label\"].map({0: 1, 1: -1})\n",
    "\n",
    "\n",
    "# Naive Bayes is a classification technique based on bayes theoram\n",
    "# The theoram works on conditional Probability and Mathematics\n",
    "\n",
    "# PRIOR PROBABILITY --> Probability of assuming before, performing the experiment.\n",
    "# LIKLIHOOD PROBABILITY --> Probability of assuming while performing the experiment.\n",
    "# POSTERIOR PROBABILITY --> Probability by combining both prior and liklihood probability.\n",
    "\n",
    "# Formula of Naive Bayes Theoram:\n",
    "#    P(A|B) = (P(B|A) * p(A)) / P(B)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "# Training the Model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
    "\n",
    "\n",
    "NB_classifier = MultinomialNB()\n",
    "NB_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Confusion Matrix --> Compares true value with predicted value \n",
    "# Predicting the Test set results\n",
    "y_predict_test = NB_classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_predict_test)\n",
    "sns.heatmap(cm, annot=True)\n",
    "\n",
    "print(classification_report(y_test, y_predict_test))\n",
    "\n",
    "# def analyze_naive_bayes():\n",
    "#     input_text = input_entry.get()\n",
    "#     input_vector = vectorizer.transform([input_text])\n",
    "#     sentiment_label = NB_classifier.predict(input_vector)[0]\n",
    "#     print(\"Sentiment Score:\", sentiment_label)  # Debugging statement\n",
    "\n",
    "#     display_sentiment(sentiment_label)\n",
    "\n",
    "\n",
    "# # Function to analyze sentiment using TextBlob\n",
    "# def analyze_textblob():\n",
    "#     input_text = input_entry.get()\n",
    "\n",
    "#     blob = TextBlob(input_text)\n",
    "#     sentiment_score = blob.sentiment.polarity\n",
    "\n",
    "#     if sentiment_score > 0:\n",
    "#         sentiment = 1\n",
    "#     elif sentiment_score < 0:\n",
    "#         sentiment = -1\n",
    "#     else:\n",
    "#         sentiment = 0\n",
    "    \n",
    "#     display_sentiment(sentiment)\n",
    "\n",
    "# # Function to analyze sentiment and update the result\n",
    "# def display_sentiment(sentiment_label):\n",
    "\n",
    "\n",
    "#     if sentiment_label == 1:\n",
    "#         sentiment = \"Positive\"\n",
    "#         image_path = \"/Users/shraddha/Documents/UEL/MYDES/positive_image.png\"\n",
    "#     elif sentiment_label == -1:\n",
    "#         sentiment = \"Negative\"\n",
    "#         image_path = \"/Users/shraddha/Documents/UEL/MYDES/negative_image.png\"\n",
    "#     else:\n",
    "#         sentiment = \"Neutral\"\n",
    "#         image_path = \"/Users/shraddha/Documents/UEL/MYDES/neutral_image.png\"\n",
    "\n",
    "#     print(\"sentiment:\", sentiment)  # Debugging statement\n",
    "\n",
    "#     # Update the result label\n",
    "#     result_label.config(text=f\"Sentiment: {sentiment}\")\n",
    "\n",
    "#     # Load and display the corresponding image\n",
    "#     image = Image.open(image_path)\n",
    "#     image = image.resize((150, 150), Image.ADAPTIVE)\n",
    "#     photo = ImageTk.PhotoImage(image=image)\n",
    "#     image_label.config(image=photo)\n",
    "#     image_label.photo = photo\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705532ee-c0b2-499f-affd-54154bd4d5cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc98d83e-e6ff-4f4e-b3b6-9cb25940c6e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
